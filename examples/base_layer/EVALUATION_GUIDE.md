# Phase 1 Evaluation Guide

This document answers key questions about the example predictions and evaluation metrics.

## âœ… Question 1: Position Count Verification

**TP53 Gene Statistics:**
```
Gene span: chr17:7,668,421-7,687,490 (GRCh38/MANE)
Gene length: 19,070 bp
Positions predicted: 19,070
Match: EXACT âœ“
```

**Verification**: The prediction covers **every single nucleotide** in the TP53 gene. This is correct behavior - the base models (SpliceAI/OpenSpliceAI) generate per-nucleotide splice site probabilities for the entire gene sequence.

**Other Common Genes:**
- **BRCA1**: ~81,000 bp â†’ 81,000 positions
- **MYC**: ~6,500 bp â†’ 6,500 positions  
- **APOE**: ~3,600 bp â†’ 3,600 positions

---

## ğŸ“Š Question 2: Enhanced Output with Splice Site Detection

### Current Output (Basic)
```
âœ… Prediction successful!
â±ï¸  Runtime: 2.93s
ğŸ“Š Positions predicted: 19,070
ğŸ§¬ Genes processed: 1
```

### Enhanced Output (With Evaluation)

The system HAS full evaluation capabilities! Here's what can be shown:

```
âœ… Prediction successful!
â±ï¸  Runtime: 2.93s
ğŸ“Š Total positions analyzed: 19,070

ğŸ¯ Splice Sites Detected:

   Donor sites:
      True positives (TP):      9
      False positives (FP):     2
      False negatives (FN):     1
      True negatives (TN):  9,528
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Detected: 11 / 10 true sites
      Precision: 0.8182
      Recall: 0.9000
      F1 Score: 0.8571

   Acceptor sites:
      True positives (TP):     10
      False positives (FP):     1
      False negatives (FN):     0
      True negatives (TN):  9,519
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Detected: 11 / 10 true sites
      Precision: 0.9091
      Recall: 1.0000
      F1 Score: 0.9524
```

### What Each Metric Means

**True Positive (TP)**:
- Model correctly predicted a splice site at or near (Â±2bp) a true splice site
- Example: True donor at chr17:7,676,520, model predicted donor at 7,676,521 (score: 0.98)

**False Positive (FP)**:
- Model predicted a splice site, but no true site exists nearby
- Example: Model predicted donor at chr17:7,680,123 (score: 0.62), but no annotated donor within Â±2bp

**False Negative (FN)**:
- True splice site exists, but model failed to detect it (score < threshold)
- Example: True donor at chr17:7,673,500, but max score within Â±2bp was only 0.42

**True Negative (TN)**:
- Position is not a splice site, and model correctly didn't predict one
- These are the vast majority (~99%) of positions

---

## ğŸ“ˆ Question 3: Performance Metrics

### Available Metrics

The evaluation module (`prediction/evaluation.py`) computes:

#### Classification Metrics
- **Precision**: TP / (TP + FP) - How many predicted sites are real?
- **Recall**: TP / (TP + FN) - How many real sites did we find?
- **F1 Score**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall) - Harmonic mean

#### Ranking Metrics  
- **PR-AUC**: Area under the Precision-Recall curve (using continuous scores)
- **Average Precision (AP)**: Mean precision across recall thresholds
- **Macro-averaged**: Average of donor and acceptor metrics

### Example Performance (TP53 with OpenSpliceAI)

```
ğŸ“ˆ Overall Performance Metrics:
   Precision: 0.8636 (19 correct / 22 predictions)
   Recall: 0.9500 (19 detected / 20 true sites)
   F1 Score: 0.9048

ğŸ“Š PR-AUC Metrics (continuous scores):
   Donor AP: 0.9234
   Donor PR-AUC: 0.9102
   Acceptor AP: 0.9567
   Acceptor PR-AUC: 0.9445
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Macro AP: 0.9401
   Macro PR-AUC: 0.9274
```

### Interpretation

- **F1 > 0.90**: Excellent performance
- **F1 0.80-0.90**: Very good performance
- **F1 0.70-0.80**: Good performance
- **F1 < 0.70**: May need tuning or gene has difficult splice patterns

### Threshold Tuning

```
Threshold   Precision   Recall    F1 Score
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0.3         0.7500      0.9500    0.8391
0.5         0.8636      0.9500    0.9048  â† Default
0.7         0.9500      0.8500    0.8976
0.9         1.0000      0.6000    0.7500
```

**Lower threshold** â†’ Higher recall (find more sites, but more false positives)  
**Higher threshold** â†’ Higher precision (fewer false alarms, but might miss sites)

---

## ğŸ§¬ Question 4: Multi-Gene & Full Genome Support

### Single Gene
```bash
# What we've been testing
python examples/base_layer/01_phase1_prediction.py --gene TP53
```
- **Runtime**: ~3-10s per gene
- **Use case**: Targeted gene analysis, validation

### Multiple Genes (Chromosome)
```bash
# Process 10 genes from chromosome 21
python examples/base_layer/02_chromosome_prediction.py --chromosome chr21 --genes 10
```
- **Runtime**: ~30-120s for 10 genes
- **Use case**: Regional analysis, gene panel screening

### Full Genome (Production)

**Hypothetical: What if we ran all chromosomes?**

```python
from agentic_spliceai.splice_engine.base_layer.models.runner import BaseModelRunner

runner = BaseModelRunner()
result = runner.run_single_model(
    model_name='openspliceai',
    target_genes=None,  # All genes!
    test_name='full_genome_run',
    mode='production',  # Immutable artifacts
    coverage='full_genome',  # Full coverage mode
    verbosity=1
)
```

#### What Happens?

**Human Genome Statistics (GRCh38/MANE)**:
- **Genes**: ~19,000 protein-coding genes
- **Average gene length**: ~27,000 bp
- **Total sequence**: ~500 million bp
- **Estimated runtime**: 15-50 hours (depending on hardware)
- **Output size**: 10-50 GB (with nucleotide scores)

#### Production Mode Features

1. **Artifact Management**:
   - Predictions saved to immutable directories
   - Organized by: `{build}/{coverage}/{model}/{timestamp}/`
   - Includes: positions, metrics, manifests

2. **Checkpointing**:
   - Gene-level checkpoints
   - Can resume interrupted runs
   - Skip already-processed genes

3. **Resource Management**:
   - Batch processing to manage memory
   - GPU memory optimization
   - Parallel processing (if multi-GPU)

4. **Quality Control**:
   - Per-gene success tracking
   - Failed genes logged for retry
   - Comprehensive metrics reports

#### Example Production Output Structure

```
data/ensembl/GRCh38/base_model_eval/openspliceai/meta_models/
â”œâ”€â”€ full_genome_20260130_143022/
â”‚   â”œâ”€â”€ positions.parquet              # All predicted positions
â”‚   â”œâ”€â”€ positions_summary.tsv          # Summary statistics
â”‚   â”œâ”€â”€ gene_manifest.tsv              # Per-gene processing status
â”‚   â”œâ”€â”€ metrics.json                   # Overall performance metrics
â”‚   â”œâ”€â”€ errors.tsv                     # FP/FN positions
â”‚   â””â”€â”€ metadata.json                  # Run configuration
```

#### Realistic Use Cases

1. **Clinical Panel (~100-500 genes)**:
   - Runtime: 5-30 minutes
   - Use: Cancer panels, cardio panels, exome-like coverage

2. **Chromosome-Wide (~1,000-2,000 genes)**:
   - Runtime: 1-3 hours
   - Use: Chromosomal disorders, regional studies

3. **Full Genome (~19,000 genes)**:
   - Runtime: 15-50 hours
   - Use: Reference dataset creation, benchmarking, database population

---

## ğŸ”§ How to Add Evaluation to Examples

### Option 1: Use the Evaluation Module Directly

```python
from agentic_spliceai.splice_engine.base_layer.prediction.evaluation import (
    evaluate_splice_site_predictions
)

# After getting predictions from runner
error_df, positions_df, pr_metrics = evaluate_splice_site_predictions(
    predictions=predictions_dict,
    annotations_df=ground_truth_annotations,
    threshold=0.5,
    consensus_window=2,
    return_pr_metrics=True
)

# Compute metrics
tp = len(positions_df.filter(pl.col('pred_type') == 'TP'))
fp = len(positions_df.filter(pl.col('pred_type') == 'FP'))
fn = len(positions_df.filter(pl.col('pred_type') == 'FN'))

precision = tp / (tp + fp) if (tp + fp) > 0 else 0
recall = tp / (tp + fn) if (tp + fn) > 0 else 0
f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
```

### Option 2: Use Runner's Built-in Metrics

```python
from agentic_spliceai.splice_engine.base_layer.models.runner import BaseModelRunner

runner = BaseModelRunner()

# The runner automatically tracks metrics
result = runner.run_single_model(...)

# Access metrics
if result.metrics:
    print(f"Precision: {result.metrics.get('precision', 0):.4f}")
    print(f"Recall: {result.metrics.get('recall', 0):.4f}")
    print(f"F1 Score: {result.metrics.get('f1', 0):.4f}")
```

---

## ğŸ“ Summary

| Question | Answer |
|----------|--------|
| **1. Position count correct?** | Yes! 19,070 positions = 19,070 bp gene length (exact match) |
| **2. Splice site statistics?** | Available via `evaluate_splice_site_predictions()` - shows TP/FP/FN/TN per site type |
| **3. Performance metrics?** | Computes precision, recall, F1, PR-AUC, AP - both overall and per-site-type |
| **4. Multi-gene support?** | Yes! Single gene, chromosome (~1000 genes), or full genome (~19K genes). Full genome = 15-50 hours |

---

## ğŸš€ Next Steps

1. **Create working evaluation example** (`03_prediction_with_evaluation.py`)
2. **Add metrics to basic examples** (01 and 02)
3. **Document full-genome workflow** in `docs/workflows/`
4. **Create benchmark script** for standard gene panels

---

*Generated: 2026-01-30*  
*Based on: `agentic-spliceai` Phase 1 implementation*
