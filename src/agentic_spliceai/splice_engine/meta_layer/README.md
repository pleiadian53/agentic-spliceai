# Meta-Layer: Base-Model-Agnostic Multimodal Meta-Learning

**Status**: ğŸš§ In Development  
**Version**: 0.1.0  
**Last Updated**: December 2025  
**Ported from**: meta_spliceai/splice_engine/meta_layer/

---

## Overview

The Meta-Layer is a **multimodal deep learning system** that recalibrates base model splice site predictions to:

1. **Correct FPs/FNs** - Reduce false positives and false negatives from base models
2. **Predict context-dependent splicing** - Account for variant-induced alternative splicing
3. **Maintain consistency** - Output same format as base layer (per-nucleotide probabilities)

### Key Design Principle: Base-Model-Agnostic

Just like the base layer supports any splice prediction model, the meta-layer works with **any base model** via a single parameter:

```python
from agentic_spliceai.splice_engine.meta_layer import MetaSpliceModel, run_canonical_training

# Works with SpliceAI (GRCh37)
result = run_canonical_training(base_model='spliceai', epochs=30)

# Works with OpenSpliceAI (GRCh38/MANE)
result = run_canonical_training(base_model='openspliceai', epochs=30)
```

---

## Model Categories

### 1. Classification Models (Canonical Splice Site Classification)

For recalibrating base model predictions on canonical splice sites:

```python
from agentic_spliceai.splice_engine.meta_layer import (
    MetaSpliceModel,      # Per-window classification (501nt â†’ [1, 3])
    MetaSpliceModelV2,    # Sequence-to-sequence (L nt â†’ [L, 3])
)
```

### 2. Splice Effect Classifiers (Variant Classification)

For predicting whether variants affect splicing:

```python
from agentic_spliceai.splice_engine.meta_layer import (
    SpliceInducingClassifier,   # Binary: Is this variant splice-altering?
    EffectTypeClassifier,       # Multi-class: What type of effect?
    UnifiedSpliceClassifier,    # Multi-task with position attention
)
```

### 3. Delta Prediction Models (Variant Effect Magnitude)

For predicting how much variants change splice site scores:

```python
from agentic_spliceai.splice_engine.meta_layer import (
    DeltaPredictor,             # Siamese network (paired prediction)
    SimpleCNNDeltaPredictor,    # Gated CNN (BEST calibrated)
    ValidatedDeltaPredictor,    # Single-pass with SpliceVarDB targets (BEST SO FAR, r=0.41)
)
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         META-LAYER ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  INPUT: Base Layer Artifacts (analysis_sequences_*.tsv)        â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  â€¢ 501nt contextual sequences                                   â”‚   â”‚
â”‚  â”‚  â€¢ Base model scores (donor, acceptor, neither)                 â”‚   â”‚
â”‚  â”‚  â€¢ 50+ derived features                                         â”‚   â”‚
â”‚  â”‚  â€¢ Labels (splice_type from GTF annotations)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SEQUENCE ENCODER (Modality 1)                                  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  Options: HyenaDNA, Gated CNN (lightweight)                     â”‚   â”‚
â”‚  â”‚  Output: [B, D] sequence embeddings                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SCORE ENCODER (Modality 2)                                     â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  MLP: [50+ features] â†’ [D] score embeddings                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FUSION LAYER                                                    â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  Cross-attention or concatenation                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  OUTPUT: Recalibrated probabilities / Delta scores              â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  Classification: P(donor), P(acceptor), P(neither)              â”‚   â”‚
â”‚  â”‚  Delta: Î”_donor, Î”_acceptor, Î”_neither                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Package Structure

```
meta_layer/
â”œâ”€â”€ __init__.py                 # Package entry point
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # MetaLayerConfig
â”‚   â”œâ”€â”€ artifact_loader.py      # Load base layer artifacts
â”‚   â”œâ”€â”€ feature_schema.py       # Standardized feature definitions
â”‚   â””â”€â”€ path_manager.py         # Safe read/write path resolution
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sequence_encoder.py     # DNA LM wrapper (HyenaDNA, CNN)
â”‚   â”œâ”€â”€ score_encoder.py        # MLP for score features
â”‚   â”œâ”€â”€ meta_splice_model.py    # Classification model (V1)
â”‚   â”œâ”€â”€ meta_splice_model_v2.py # Seq2seq model (V2)
â”‚   â”œâ”€â”€ splice_classifier.py    # Variant effect classifiers
â”‚   â”œâ”€â”€ delta_predictor.py      # Siamese delta predictor
â”‚   â”œâ”€â”€ delta_predictor_v2.py   # Per-position delta
â”‚   â”œâ”€â”€ validated_delta_predictor.py  # SpliceVarDB-validated (BEST)
â”‚   â”œâ”€â”€ hyenadna_delta_predictor.py   # SimpleCNNDeltaPredictor
â”‚   â”œâ”€â”€ hyenadna_encoder.py     # HyenaDNA integration
â”‚   â””â”€â”€ delta_predictor_calibrated.py # Calibration strategies
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py              # MetaLayerDataset
â”‚   â”œâ”€â”€ splicevardb_loader.py   # SpliceVarDB integration
â”‚   â””â”€â”€ variant_dataset.py      # VariantDeltaDataset
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py              # Training loop
â”‚   â”œâ”€â”€ evaluator.py            # Metrics (PR-AUC, top-k)
â”‚   â””â”€â”€ variant_evaluator.py    # Variant effect evaluation
â”‚
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ predictor.py            # Inference engine
â”‚   â”œâ”€â”€ base_model_predictor.py # Base model wrapper
â”‚   â”œâ”€â”€ full_coverage_inference.py   # From scratch
â”‚   â””â”€â”€ full_coverage_predictor.py   # From artifacts
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ canonical_training.py   # Canonical classification training
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ default.yaml            # Default configuration
â”‚   â”œâ”€â”€ lightweight.yaml        # M1 Mac optimized
â”‚   â””â”€â”€ hyenadna.yaml           # GPU training with HyenaDNA
â”‚
â””â”€â”€ docs/                       # Package documentation
```

---

## Quick Start

### 1. Train on Canonical Splice Sites

```python
from agentic_spliceai.splice_engine.meta_layer import run_canonical_training

# Train with lightweight CNN (CPU-friendly for M1 Mac)
result = run_canonical_training(
    base_model='openspliceai',
    epochs=30,
    sequence_encoder='cnn',
    output_dir='./experiments/canonical_v1'
)

print(f"Test PR-AUC: {result.canonical_test_metrics['pr_auc_macro']:.4f}")
if result.variant_evaluation:
    print(result.variant_evaluation.summary())
```

### 2. Create Delta Predictor

```python
from agentic_spliceai.splice_engine.meta_layer import (
    ValidatedDeltaPredictor,
    create_validated_delta_predictor
)

# Create model
model = create_validated_delta_predictor(
    variant='attention',  # With position attention
    hidden_dim=128,
    n_layers=6
)

# Forward pass
delta = model(alt_seq, ref_base, alt_base)  # [B, 3]
```

### 3. Use Calibrated Predictor

```python
from agentic_spliceai.splice_engine.meta_layer import (
    SimpleCNNDeltaPredictor,
    create_calibrated_predictor
)

# Create base predictor
base = SimpleCNNDeltaPredictor(hidden_dim=64)

# Wrap with quantile calibration (BEST for large deltas)
model = create_calibrated_predictor(
    base_predictor=base,
    strategy='quantile',
    quantile=0.9
)
```

---

## Training Workflows

| Workflow | Description | Status |
|----------|-------------|--------|
| `canonical_training.py` | Train on canonical sites, evaluate on variants | âœ… Implemented |
| `validated_delta_training.py` | Delta prediction with SpliceVarDB targets | ğŸ“‹ TODO |
| `hyenadna_training.py` | GPU training with HyenaDNA | ğŸ“‹ TODO |

---

## Best Approaches (from R&D)

Based on experiments in meta-spliceai:

1. **ValidatedDeltaPredictor** with SpliceVarDB targets: r=0.41 correlation
2. **SimpleCNNDeltaPredictor** with quantile loss (Ï„=0.9): Best calibration
3. **Gated CNN with dilated convolutions**: Captures long-range patterns
4. **LayerNorm + GELU**: Better than BatchNorm + ReLU for this task

Things that **didn't work**:
- Simple scaling/temperature calibration
- MSE loss alone (need quantile loss)
- More data without architecture improvements

---

## Configurations

| Config | Environment | Sequence Encoder | Notes |
|--------|-------------|------------------|-------|
| `default.yaml` | General | CNN | Balanced defaults |
| `lightweight.yaml` | M1 Mac | CNN | 32-dim, reduced epochs |
| `hyenadna.yaml` | GPU | HyenaDNA | Full capacity |

---

## Requirements

- Python 3.10+
- PyTorch 2.0+
- polars, numpy
- scikit-learn
- tqdm

Optional:
- transformers (for HyenaDNA)
- CUDA GPU (for full training)

---

## Status

| Component | Status |
|-----------|--------|
| Core config | âœ… Complete |
| Artifact loader | âœ… Complete |
| Models - Classification | âœ… Complete |
| Models - Delta prediction | âœ… Complete |
| Dataset preparation | âœ… Complete |
| Training pipeline | âœ… Complete |
| Evaluation | âœ… Complete |
| Inference | âœ… Complete |
| Workflows | ğŸš§ In progress |
| CLI | ğŸ“‹ Planned |

---

*Ported from meta_spliceai with updated import paths and improved naming conventions.*  
*Last Updated: December 2025*












